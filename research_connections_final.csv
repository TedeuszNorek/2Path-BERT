From;To;Direction;Label;Type;Tags;Description;Experiment ID;Base Model;Model Configuration;Link;Analysis prompt;Text;Temperature;[Engineer];Timestamp
Scientists;experiments;positive;;;;;1;BERT;None;conducted;Extract semantic relationships from scientific text;Scientists conducted experiments on neural networks. Machine learning algorithms showed promising results in data processing tasks.;1.0;;2025-06-10T21:17:07.818328
Machine learning algorithms;promising results;positive;;;;;1;BERT;None;showed;Extract semantic relationships from scientific text;Scientists conducted experiments on neural networks. Machine learning algorithms showed promising results in data processing tasks.;1.0;;2025-06-10T21:17:07.818328
algorithms;data;positive;;;;;1;BERT;None;process;Extract semantic relationships from scientific text;Scientists conducted experiments on neural networks. Machine learning algorithms showed promising results in data processing tasks.;1.0;;2025-06-10T21:17:07.818328
Researchers;graph neural networks;positive;;;;;2;BERT;RGCN;analyzed;Compare RGCN enhancement to baseline;Researchers analyzed graph neural networks for relationship extraction. RGCN models demonstrated improved performance on heterogeneous graphs.;1.0;;2025-06-10T21:17:07.821961
RGCN models;improved performance;positive;;;;;2;BERT;RGCN;demonstrated;Compare RGCN enhancement to baseline;Researchers analyzed graph neural networks for relationship extraction. RGCN models demonstrated improved performance on heterogeneous graphs.;1.0;;2025-06-10T21:17:07.821961
models;heterogeneous graphs;positive;;;;;2;BERT;RGCN;work on;Compare RGCN enhancement to baseline;Researchers analyzed graph neural networks for relationship extraction. RGCN models demonstrated improved performance on heterogeneous graphs.;1.0;;2025-06-10T21:17:07.821961
Deep learning architectures;attention mechanisms;positive;;;;;3;BERT;COMPGCN;utilize;Evaluate composition-based GNN approach;Deep learning architectures utilize attention mechanisms. CompGCN models jointly embed entities and relations in unified space.;1.2;;2025-06-10T21:17:07.821980
CompGCN models;entities and relations;positive;;;;;3;BERT;COMPGCN;embed;Evaluate composition-based GNN approach;Deep learning architectures utilize attention mechanisms. CompGCN models jointly embed entities and relations in unified space.;1.2;;2025-06-10T21:17:07.821980
models;unified space;positive;;;;;3;BERT;COMPGCN;operate in;Evaluate composition-based GNN approach;Deep learning architectures utilize attention mechanisms. CompGCN models jointly embed entities and relations in unified space.;1.2;;2025-06-10T21:17:07.821980
Attention networks;semantic connections;positive;;;;;4;BERT;RGAT;focus on;Test attention-based graph processing;Attention networks focus on relevant semantic connections. RGAT provides interpretable relationship importance weights.;0.8;;2025-06-10T21:17:07.821986
RGAT;interpretable weights;positive;;;;;4;BERT;RGAT;provides;Test attention-based graph processing;Attention networks focus on relevant semantic connections. RGAT provides interpretable relationship importance weights.;0.8;;2025-06-10T21:17:07.821986
weights;relationship importance;positive;;;;;4;BERT;RGAT;indicate;Test attention-based graph processing;Attention networks focus on relevant semantic connections. RGAT provides interpretable relationship importance weights.;0.8;;2025-06-10T21:17:07.821986
